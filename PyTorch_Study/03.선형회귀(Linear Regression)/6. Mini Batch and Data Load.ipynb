{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNB2RtKC6i/50KH2Ic7qQyA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"WKOco60dst76","executionInfo":{"status":"ok","timestamp":1674550914374,"user_tz":-540,"elapsed":4630,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","source":["https://wikidocs.net/55580"],"metadata":{"id":"8oN9HBvyx9Sc"}},{"cell_type":"code","source":["# TensorDataset과 DataLoader를 임포트\n","from torch.utils.data import TensorDataset # 텐서데이터셋\n","from torch.utils.data import DataLoader # 데이터로더"],"metadata":{"id":"1G2IyC55tJHv","executionInfo":{"status":"ok","timestamp":1674550915865,"user_tz":-540,"elapsed":1,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# TensorDataset은 기본적으로 텐서를 입력으로 받습니다. 텐서 형태로 데이터를 정의합니다.\n","\n","x_train  =  torch.FloatTensor([[73,  80,  75], \n","                               [93,  88,  93], \n","                               [89,  91,  90], \n","                               [96,  98,  100],   \n","                               [73,  66,  70]])  \n","y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"],"metadata":{"id":"Bj1lpv7EtQ7K","executionInfo":{"status":"ok","timestamp":1674550917704,"user_tz":-540,"elapsed":1,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["dataset = TensorDataset(x_train, y_train)"],"metadata":{"id":"SzBSx5DOtVXa","executionInfo":{"status":"ok","timestamp":1674550927559,"user_tz":-540,"elapsed":315,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["파이토치의 데이터셋을 만들었다면 데이터로더를 사용 가능합니다. 데이터로더는 기본적으로 2개의 인자를 입력받는다. 하나는 데이터셋, 미니 배치의 크기입니다. 이때 미니 배치의 크기는 통상적으로 2의 배수를 사용합니다. (ex) 64, 128, 256...) 그리고 추가적으로 많이 사용되는 인자로 shuffle이 있습니다. shuffle=True를 선택하면 Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꿉니다."],"metadata":{"id":"7RLDouD0thQl"}},{"cell_type":"markdown","source":["사람도 같은 문제지를 계속 풀면 어느 순간 문제의 순서에 익숙해질 수 있습니다. 예를 들어 어떤 문제지의 12번 문제를 풀면서, '13번 문제가 뭔지는 기억은 안 나지만 어제 풀었던 기억으로 정답은 5번이었던 것 같은데' 하면서 문제 자체보단 순서에 익숙해질 수 있다는 것입니다. 그럴 때 문제지를 풀 때마다 문제 순서를 랜덤으로 바꾸면 도움이 될 겁니다. 마찬가지로 모델이 데이터셋의 순서에 익숙해지는 것을 방지하여 학습할 때는 이 옵션을 True를 주는 것을 권장합니다."],"metadata":{"id":"DO0SQu6ctkeI"}},{"cell_type":"code","source":["dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"H6r58h7YthuS","executionInfo":{"status":"ok","timestamp":1674550929553,"user_tz":-540,"elapsed":275,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model  = nn.Linear(3, 1)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)"],"metadata":{"id":"Hc95pLpKtnkH","executionInfo":{"status":"ok","timestamp":1674550938312,"user_tz":-540,"elapsed":314,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","  for batch_idx, samples in enumerate(dataloader):\n","    print('batch_idx:', batch_idx)\n","    print(samples)\n","    x_train, y_train = samples\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # cost로 H(x) 계산\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","        ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVNLbh1bt6sH","executionInfo":{"status":"ok","timestamp":1674550956248,"user_tz":-540,"elapsed":387,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"a4ca90dd-69fa-4297-b1b2-27b6c7f5a833"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["batch_idx: 0\n","[tensor([[93., 88., 93.],\n","        [89., 91., 90.]]), tensor([[185.],\n","        [180.]])]\n","Epoch    0/20 Batch 1/3 Cost: 0.466912\n","batch_idx: 1\n","[tensor([[ 73.,  80.,  75.],\n","        [ 96.,  98., 100.]]), tensor([[152.],\n","        [196.]])]\n","Epoch    0/20 Batch 2/3 Cost: 2.246754\n","batch_idx: 2\n","[tensor([[73., 66., 70.]]), tensor([[142.]])]\n","Epoch    0/20 Batch 3/3 Cost: 4.209146\n","batch_idx: 0\n","[tensor([[89., 91., 90.],\n","        [73., 66., 70.]]), tensor([[180.],\n","        [142.]])]\n","Epoch    1/20 Batch 1/3 Cost: 1.564251\n","batch_idx: 1\n","[tensor([[ 96.,  98., 100.],\n","        [ 93.,  88.,  93.]]), tensor([[196.],\n","        [185.]])]\n","Epoch    1/20 Batch 2/3 Cost: 2.940664\n","batch_idx: 2\n","[tensor([[73., 80., 75.]]), tensor([[152.]])]\n","Epoch    1/20 Batch 3/3 Cost: 0.301883\n","batch_idx: 0\n","[tensor([[73., 66., 70.],\n","        [89., 91., 90.]]), tensor([[142.],\n","        [180.]])]\n","Epoch    2/20 Batch 1/3 Cost: 1.733682\n","batch_idx: 1\n","[tensor([[ 73.,  80.,  75.],\n","        [ 96.,  98., 100.]]), tensor([[152.],\n","        [196.]])]\n","Epoch    2/20 Batch 2/3 Cost: 2.359245\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch    2/20 Batch 3/3 Cost: 0.573632\n","batch_idx: 0\n","[tensor([[ 96.,  98., 100.],\n","        [ 73.,  80.,  75.]]), tensor([[196.],\n","        [152.]])]\n","Epoch    3/20 Batch 1/3 Cost: 2.041276\n","batch_idx: 1\n","[tensor([[73., 66., 70.],\n","        [89., 91., 90.]]), tensor([[142.],\n","        [180.]])]\n","Epoch    3/20 Batch 2/3 Cost: 2.204393\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch    3/20 Batch 3/3 Cost: 0.237719\n","batch_idx: 0\n","[tensor([[ 73.,  80.,  75.],\n","        [ 96.,  98., 100.]]), tensor([[152.],\n","        [196.]])]\n","Epoch    4/20 Batch 1/3 Cost: 2.306505\n","batch_idx: 1\n","[tensor([[89., 91., 90.],\n","        [93., 88., 93.]]), tensor([[180.],\n","        [185.]])]\n","Epoch    4/20 Batch 2/3 Cost: 0.327991\n","batch_idx: 2\n","[tensor([[73., 66., 70.]]), tensor([[142.]])]\n","Epoch    4/20 Batch 3/3 Cost: 3.749000\n","batch_idx: 0\n","[tensor([[73., 66., 70.],\n","        [89., 91., 90.]]), tensor([[142.],\n","        [180.]])]\n","Epoch    5/20 Batch 1/3 Cost: 1.555487\n","batch_idx: 1\n","[tensor([[93., 88., 93.],\n","        [73., 80., 75.]]), tensor([[185.],\n","        [152.]])]\n","Epoch    5/20 Batch 2/3 Cost: 0.005099\n","batch_idx: 2\n","[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n","Epoch    5/20 Batch 3/3 Cost: 6.034753\n","batch_idx: 0\n","[tensor([[89., 91., 90.],\n","        [73., 66., 70.]]), tensor([[180.],\n","        [142.]])]\n","Epoch    6/20 Batch 1/3 Cost: 2.932775\n","batch_idx: 1\n","[tensor([[ 96.,  98., 100.],\n","        [ 73.,  80.,  75.]]), tensor([[196.],\n","        [152.]])]\n","Epoch    6/20 Batch 2/3 Cost: 1.483492\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch    6/20 Batch 3/3 Cost: 1.076609\n","batch_idx: 0\n","[tensor([[93., 88., 93.],\n","        [73., 80., 75.]]), tensor([[185.],\n","        [152.]])]\n","Epoch    7/20 Batch 1/3 Cost: 0.239941\n","batch_idx: 1\n","[tensor([[73., 66., 70.],\n","        [89., 91., 90.]]), tensor([[142.],\n","        [180.]])]\n","Epoch    7/20 Batch 2/3 Cost: 1.654723\n","batch_idx: 2\n","[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n","Epoch    7/20 Batch 3/3 Cost: 4.979485\n","batch_idx: 0\n","[tensor([[89., 91., 90.],\n","        [73., 80., 75.]]), tensor([[180.],\n","        [152.]])]\n","Epoch    8/20 Batch 1/3 Cost: 0.716224\n","batch_idx: 1\n","[tensor([[73., 66., 70.],\n","        [93., 88., 93.]]), tensor([[142.],\n","        [185.]])]\n","Epoch    8/20 Batch 2/3 Cost: 3.023416\n","batch_idx: 2\n","[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n","Epoch    8/20 Batch 3/3 Cost: 4.087880\n","batch_idx: 0\n","[tensor([[ 73.,  66.,  70.],\n","        [ 96.,  98., 100.]]), tensor([[142.],\n","        [196.]])]\n","Epoch    9/20 Batch 1/3 Cost: 3.588360\n","batch_idx: 1\n","[tensor([[89., 91., 90.],\n","        [73., 80., 75.]]), tensor([[180.],\n","        [152.]])]\n","Epoch    9/20 Batch 2/3 Cost: 0.522438\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch    9/20 Batch 3/3 Cost: 0.861937\n","batch_idx: 0\n","[tensor([[93., 88., 93.],\n","        [73., 80., 75.]]), tensor([[185.],\n","        [152.]])]\n","Epoch   10/20 Batch 1/3 Cost: 0.194620\n","batch_idx: 1\n","[tensor([[ 96.,  98., 100.],\n","        [ 73.,  66.,  70.]]), tensor([[196.],\n","        [142.]])]\n","Epoch   10/20 Batch 2/3 Cost: 3.583165\n","batch_idx: 2\n","[tensor([[89., 91., 90.]]), tensor([[180.]])]\n","Epoch   10/20 Batch 3/3 Cost: 0.250305\n","batch_idx: 0\n","[tensor([[73., 66., 70.],\n","        [93., 88., 93.]]), tensor([[142.],\n","        [185.]])]\n","Epoch   11/20 Batch 1/3 Cost: 2.340382\n","batch_idx: 1\n","[tensor([[89., 91., 90.],\n","        [73., 80., 75.]]), tensor([[180.],\n","        [152.]])]\n","Epoch   11/20 Batch 2/3 Cost: 0.357946\n","batch_idx: 2\n","[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n","Epoch   11/20 Batch 3/3 Cost: 4.069698\n","batch_idx: 0\n","[tensor([[73., 80., 75.],\n","        [73., 66., 70.]]), tensor([[152.],\n","        [142.]])]\n","Epoch   12/20 Batch 1/3 Cost: 3.967956\n","batch_idx: 1\n","[tensor([[ 93.,  88.,  93.],\n","        [ 96.,  98., 100.]]), tensor([[185.],\n","        [196.]])]\n","Epoch   12/20 Batch 2/3 Cost: 1.596453\n","batch_idx: 2\n","[tensor([[89., 91., 90.]]), tensor([[180.]])]\n","Epoch   12/20 Batch 3/3 Cost: 0.003383\n","batch_idx: 0\n","[tensor([[89., 91., 90.],\n","        [93., 88., 93.]]), tensor([[180.],\n","        [185.]])]\n","Epoch   13/20 Batch 1/3 Cost: 0.489808\n","batch_idx: 1\n","[tensor([[ 73.,  80.,  75.],\n","        [ 96.,  98., 100.]]), tensor([[152.],\n","        [196.]])]\n","Epoch   13/20 Batch 2/3 Cost: 1.473637\n","batch_idx: 2\n","[tensor([[73., 66., 70.]]), tensor([[142.]])]\n","Epoch   13/20 Batch 3/3 Cost: 5.002051\n","batch_idx: 0\n","[tensor([[93., 88., 93.],\n","        [89., 91., 90.]]), tensor([[185.],\n","        [180.]])]\n","Epoch   14/20 Batch 1/3 Cost: 0.355650\n","batch_idx: 1\n","[tensor([[ 96.,  98., 100.],\n","        [ 73.,  80.,  75.]]), tensor([[196.],\n","        [152.]])]\n","Epoch   14/20 Batch 2/3 Cost: 2.097244\n","batch_idx: 2\n","[tensor([[73., 66., 70.]]), tensor([[142.]])]\n","Epoch   14/20 Batch 3/3 Cost: 4.274198\n","batch_idx: 0\n","[tensor([[ 89.,  91.,  90.],\n","        [ 96.,  98., 100.]]), tensor([[180.],\n","        [196.]])]\n","Epoch   15/20 Batch 1/3 Cost: 3.256826\n","batch_idx: 1\n","[tensor([[73., 66., 70.],\n","        [93., 88., 93.]]), tensor([[142.],\n","        [185.]])]\n","Epoch   15/20 Batch 2/3 Cost: 2.675491\n","batch_idx: 2\n","[tensor([[73., 80., 75.]]), tensor([[152.]])]\n","Epoch   15/20 Batch 3/3 Cost: 0.069161\n","batch_idx: 0\n","[tensor([[73., 80., 75.],\n","        [93., 88., 93.]]), tensor([[152.],\n","        [185.]])]\n","Epoch   16/20 Batch 1/3 Cost: 0.027299\n","batch_idx: 1\n","[tensor([[89., 91., 90.],\n","        [73., 66., 70.]]), tensor([[180.],\n","        [142.]])]\n","Epoch   16/20 Batch 2/3 Cost: 1.558580\n","batch_idx: 2\n","[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n","Epoch   16/20 Batch 3/3 Cost: 5.578465\n","batch_idx: 0\n","[tensor([[73., 66., 70.],\n","        [73., 80., 75.]]), tensor([[142.],\n","        [152.]])]\n","Epoch   17/20 Batch 1/3 Cost: 3.567136\n","batch_idx: 1\n","[tensor([[ 96.,  98., 100.],\n","        [ 89.,  91.,  90.]]), tensor([[196.],\n","        [180.]])]\n","Epoch   17/20 Batch 2/3 Cost: 1.611326\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch   17/20 Batch 3/3 Cost: 1.359592\n","batch_idx: 0\n","[tensor([[ 89.,  91.,  90.],\n","        [ 96.,  98., 100.]]), tensor([[180.],\n","        [196.]])]\n","Epoch   18/20 Batch 1/3 Cost: 1.639199\n","batch_idx: 1\n","[tensor([[73., 66., 70.],\n","        [73., 80., 75.]]), tensor([[142.],\n","        [152.]])]\n","Epoch   18/20 Batch 2/3 Cost: 3.215308\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch   18/20 Batch 3/3 Cost: 0.255523\n","batch_idx: 0\n","[tensor([[ 96.,  98., 100.],\n","        [ 89.,  91.,  90.]]), tensor([[196.],\n","        [180.]])]\n","Epoch   19/20 Batch 1/3 Cost: 2.513766\n","batch_idx: 1\n","[tensor([[73., 80., 75.],\n","        [73., 66., 70.]]), tensor([[152.],\n","        [142.]])]\n","Epoch   19/20 Batch 2/3 Cost: 2.825833\n","batch_idx: 2\n","[tensor([[93., 88., 93.]]), tensor([[185.]])]\n","Epoch   19/20 Batch 3/3 Cost: 0.159873\n","batch_idx: 0\n","[tensor([[ 73.,  66.,  70.],\n","        [ 96.,  98., 100.]]), tensor([[142.],\n","        [196.]])]\n","Epoch   20/20 Batch 1/3 Cost: 3.622124\n","batch_idx: 1\n","[tensor([[89., 91., 90.],\n","        [93., 88., 93.]]), tensor([[180.],\n","        [185.]])]\n","Epoch   20/20 Batch 2/3 Cost: 0.253540\n","batch_idx: 2\n","[tensor([[73., 80., 75.]]), tensor([[152.]])]\n","Epoch   20/20 Batch 3/3 Cost: 0.203487\n"]}]},{"cell_type":"code","source":["# 임의의 입력 [73, 80, 75]를 선언\n","new_var =  torch.FloatTensor([[73, 80, 75]]) \n","# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n","pred_y = model(new_var) \n","print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAsLvZYku1T0","executionInfo":{"status":"ok","timestamp":1674550976057,"user_tz":-540,"elapsed":306,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"b844a34e-3d34-4fe7-df18-b77e7b578de4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.7055]], grad_fn=<AddmmBackward0>)\n"]}]}]}