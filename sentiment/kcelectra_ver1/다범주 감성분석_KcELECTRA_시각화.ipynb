{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ip6LAGTHOO0s"},"outputs":[],"source":["def fix_font():\n","    # From https://HC.Dle.pw, By Jinseo Kim\n","    # v1.0.0\n","    import os\n","    import matplotlib as mpl\n","    import matplotlib.pyplot as plt\n","    os.system(\"apt-get install -y fonts-nanum\")\n","    os.system(\"fc-cache -fv\")\n","    mpl.font_manager._rebuild()\n","    findfont = mpl.font_manager.fontManager.findfont\n","    mpl.font_manager.findfont = findfont\n","    mpl.backends.backend_agg.findfont = findfont\n","    plt.rcParams['font.family'] = \"NanumBarunGothic\"\n","    plt.rcParams['axes.unicode_minus'] = False\n","           \n","fix_font()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9870,"status":"ok","timestamp":1676438497537,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"gJQmVka3HKQA","outputId":"241e5db7-e395-469c-ab8c-af260ff06697"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["57c1aec930af480498a534696914dcee","a5a09106148a4e20aef677ef8b708341","f17d21396ddb4943bb6bb8b4d8d70138","62f4d042e799404b85c4f98c250665e0","679e6102da26434486690477220b2a69","629c6afc4cd448fcb2226770da47c4ef","65acfec66e2940fea8386b2dcbc545b7","700273b1d89e4a98aaf429e9c3c531df","209de8577f5f44098492b54f0a8226c0","a8415d40351f4c4780b465e97441468e","81a488705e884c3bb2327e77b77850a2","6452ad161c1741d088b9d1f8143bb11a","018bc9a2b8384ffca92758977e5b397a","ae08e5667e794c5fabf64e54c67ccaec","51959f1409f8466580206ea16d72a2eb","116576bf73e94256a41f107fcd5735e3","ab911a53df904f7d820fb62ee0d6f20d","43337cdfb4f6470bb9226a38f1420c2e","0af86aa8072042498dcfb29165c327cb","be45dea373494ec9932c8da89ec3d7f6","539363cd9274415cacf894a1d8c6e82d","6574eb1017cc4db692286cea1f6bd1c5","6aa9a7149b5546018cf3c2c6a47509c8","84974d16c1e9496eb5216d6ba1fa46c0","efcd6695385a42f28f75179e5c0bde68","9ffcdd014b8f49a8b03196d486ce5195","9ca48c98404d48948ba48e733d4ba439","93191853ab014e8c8f1ea60fd8069232","b64b1011650d4ff7b9b5688fdee9ff5e","4b7d05bb589341b483e7b886ba45e42b","e453643cdeea447cb195b61d1e4f902e","133d2a8d3cce4bc58e7c4f618d8d59ff","4104db99b69d495aaab745ffaa1650d1","7e3605b73c6e428f8a2b93ec5f8fd223","a354c4f6f1a04103b3ff51670b2d996b","fe2b30d5921a43e6be1e14a65c2614b7","f7a5bd05899e429c86159c5a5ec338dd","2fb1e402bdb74114a7e5c559145e7c23","dd23a2c4115744e1b3454345475cb293","341c5c65c2924f41afbb6f3e280199a8","ce369847c3c9481c959502cea0bf66e9","0d76e6b18fbf4fe58448cc3823cc58b4","4904f7fe5cc04023bf2b871b87d81c4b","a2ae3e91f0bc490b9086b6ddde5195d2"]},"executionInfo":{"elapsed":13839,"status":"ok","timestamp":1676438515876,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"pjC_IT2VFXFO","outputId":"0dbccad2-f2da-4921-846a-1d5e8eb2f687"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c1aec930af480498a534696914dcee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/504 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6452ad161c1741d088b9d1f8143bb11a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/450k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa9a7149b5546018cf3c2c6a47509c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e3605b73c6e428f8a2b93ec5f8fd223"}},"metadata":{}}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":685,"status":"ok","timestamp":1676438518411,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"tSzJEzP2yhIS","outputId":"e2264ad7-08b4-4073-9a26-dd40f40568ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id                                               text  labels\n","0          1                          일은 왜 해도 해도 끝이 없을까? 화가 난다.       2\n","1          2     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.       2\n","2          3  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...       2\n","3          4  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...       2\n","4          5              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.       2\n","...      ...                                                ...     ...\n","51625  51626     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.       2\n","51626  51627        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.       3\n","51627  51628   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.       5\n","51628  51629  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.       3\n","51629  51630  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.       5\n","\n","[51630 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-9d69a509-1dc4-4476-bd5d-246a890ad088\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>51625</th>\n","      <td>51626</td>\n","      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>51626</th>\n","      <td>51627</td>\n","      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>51627</th>\n","      <td>51628</td>\n","      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>51628</th>\n","      <td>51629</td>\n","      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>51629</th>\n","      <td>51630</td>\n","      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>51630 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d69a509-1dc4-4476-bd5d-246a890ad088')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9d69a509-1dc4-4476-bd5d-246a890ad088 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9d69a509-1dc4-4476-bd5d-246a890ad088');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["train_df = pd.read_csv('/content/drive/MyDrive/sentiment_kcelectra/감성대화말뭉치_Training.csv')\n","train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1676438521574,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"prO7W9dWOD0Q","outputId":"db230cee-a519-4465-e5b3-1e066ea6b6fc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                               text  labels\n","0        1  이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...       3\n","1        2              회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.       3\n","2        3                      상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워.       3\n","3        4          이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.       3\n","4        5                       직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼.       3\n","...    ...                                                ...     ...\n","6636  6637  나랑 비슷한 시기에 결혼하는 친구는 시댁에서 집을 해줘서 너무 부러워. 우리는 대출...       4\n","6637  6638    친구 한 명이 결혼해서 아이를 가졌는데 너무 행복해 보이더라. 기분이 좋지만은 않아.       4\n","6638  6639      남들은 결혼 전에 일억을 모았다는데 난 뭐를 한 것인지 모르겠어. 자괴감만 드네.       4\n","6639  6640  나보다 결혼을 먼저 한 친구가 부러워. 그 친구 남편은 직장도 내 남편보다 좋고 키...       4\n","6640  6641                        친구들 모두 결혼하고 나만 혼자 남아서 쓸쓸하네.       4\n","\n","[6641 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-a42ec43f-b936-4607-b47e-a8ac134cdacd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6636</th>\n","      <td>6637</td>\n","      <td>나랑 비슷한 시기에 결혼하는 친구는 시댁에서 집을 해줘서 너무 부러워. 우리는 대출...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6637</th>\n","      <td>6638</td>\n","      <td>친구 한 명이 결혼해서 아이를 가졌는데 너무 행복해 보이더라. 기분이 좋지만은 않아.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6638</th>\n","      <td>6639</td>\n","      <td>남들은 결혼 전에 일억을 모았다는데 난 뭐를 한 것인지 모르겠어. 자괴감만 드네.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6639</th>\n","      <td>6640</td>\n","      <td>나보다 결혼을 먼저 한 친구가 부러워. 그 친구 남편은 직장도 내 남편보다 좋고 키...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6640</th>\n","      <td>6641</td>\n","      <td>친구들 모두 결혼하고 나만 혼자 남아서 쓸쓸하네.</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6641 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a42ec43f-b936-4607-b47e-a8ac134cdacd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a42ec43f-b936-4607-b47e-a8ac134cdacd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a42ec43f-b936-4607-b47e-a8ac134cdacd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["test_df = pd.read_csv('/content/drive/MyDrive/sentiment_kcelectra/감성대화말뭉치_Test.csv')\n","test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOrrZgc5O0NM"},"outputs":[],"source":["tokenized_train_sentences = tokenizer(\n","    list(train_df[\"text\"]),\n","    return_tensors= \"pt\",        # pytorch의 tensor 형태로 return\n","    max_length = 128,            # 최대 토큰 길이\n","    padding = True,              # 제로패팅\n","    truncation = True,           # 최대 토큰 길이 초과하면 자름\n","    add_special_tokens = True,   # special token 추가가\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675922913147,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"yk1YbNZRP7F0","outputId":"2db0b408-ca08-40e9-a64a-bb98c14db5c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoding(num_tokens=68, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '일은', '왜', '해도', '해도', '끝이', '없을까', '?', '화가', '난다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 10327, 2607, 8514, 8514, 12196, 23565, 33, 10406, 10805, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(tokenized_train_sentences[0])\n","print(tokenized_train_sentences[0].tokens)\n","print(tokenized_train_sentences[0].ids)\n","print(tokenized_train_sentences[0].attention_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HU81R98nQlKQ"},"outputs":[],"source":["tokenized_test_sentences = tokenizer(\n","    list(test_df[\"text\"]),\n","    return_tensors= \"pt\",        # pytorch의 tensor 형태로 return\n","    max_length = 128,            # 최대 토큰 길이\n","    padding = True,              # 제로패팅\n","    truncation = True,           # 최대 토큰 길이 초과하면 자름\n","    add_special_tokens = True,   # special token 추가가\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675922914087,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"WiYtIHaxQrOp","outputId":"d9a93a9c-1eff-4528-b9cf-2ca43cbae56d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoding(num_tokens=44, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '이번', '프로젝트', '##에서', '발표', '##를', '하는데', '내가', '실수', '##하는', '바람에', '우리', '팀', '##이', '감점', '##을', '받았', '##어', '.', '너무', '미안해', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 8183, 27504, 7979, 9716, 4023, 8504, 8241, 11400, 7974, 20786, 7992, 3634, 4012, 48171, 4053, 9667, 4006, 18, 8072, 20001, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(tokenized_test_sentences[0])\n","print(tokenized_test_sentences[0].tokens)\n","print(tokenized_test_sentences[0].ids)\n","print(tokenized_test_sentences[0].attention_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkOlLzhXRyP4"},"outputs":[],"source":["class SentimentDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rndvkzQkUN2F"},"outputs":[],"source":["train_label = train_df[\"labels\"].values\n","test_label = test_df[\"labels\"].values\n","\n","train_dataset = SentimentDataset(tokenized_train_sentences, train_label)\n","test_dataset = SentimentDataset(tokenized_test_sentences, test_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"deHdn6yNU1VJ","executionInfo":{"status":"ok","timestamp":1676438983099,"user_tz":-540,"elapsed":344,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a081422-ff23-49ec-d89f-732fdd69e1ca"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/sentiment_kcelectra/',           # 학습결과 저장경로\n","    num_train_epochs=1,                             # 학습 에포크 설정\n","    per_device_train_batch_size=64,                 # 학습 배치 사이즈 설정\n","    per_device_eval_batch_size=64,                  # 테스트 배치 사이즈 설정  \n","    logging_dir='/content/drive/MyDrive/sentiment_kcelectra/logs',      # 학습 log 저장 경로\n","    logging_steps=500,                              # 학습 log 기록 단위\n","    save_total_limit=2,                              # 학습 결과 저장 최대 갯수\n","    resume_from_checkpoint=True\n",")   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mee6Z0O1XdN_"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support, accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A8hdK9FqXlJZ"},"outputs":[],"source":["# 평가지표를 위한 함수\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average = 'macro')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy' : acc,\n","        'f1' : f1,\n","        'precision' : precision,\n","        'recall' : recall\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9602,"status":"ok","timestamp":1676439025865,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"0j0AHDMUXNhH","outputId":"e6f9b556-221e-48b6-9d5f-ca3b5c385cd3"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500/config.json\n","Model config ElectraConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500\",\n","  \"architectures\": [\n","    \"ElectraForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.2,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 54343\n","}\n","\n","loading weights file /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500/pytorch_model.bin\n","All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n","\n","All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"]},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.2, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.2, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":34}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXxwCGeRYZUJ"},"outputs":[],"source":["trainer = Trainer(\n","    model = model,\n","    args = args,\n","    train_dataset = train_dataset,\n","    eval_dataset = test_dataset,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OFD1RXvYgHa","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"error","timestamp":1676272520377,"user_tz":-540,"elapsed":2691,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"9ac62a1a-8c82-4640-b11a-0c27f0ee4eb5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 51630\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 807\n","  Number of trainable parameters = 127781382\n","<ipython-input-8-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2569\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2571\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2572\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2573\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         discriminator_hidden_states = self.electra(\n\u001b[0m\u001b[1;32m   1004\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    585\u001b[0m                 )\n\u001b[1;32m    586\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    588\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"executionInfo":{"elapsed":15378,"status":"ok","timestamp":1676439046668,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"pf--CjZqifCI","outputId":"ff4dd321-9609-485d-8805-13c23aedf450"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 6641\n","  Batch size = 64\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [104/104 00:15]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.8327698707580566,\n"," 'eval_accuracy': 0.732419816292727,\n"," 'eval_f1': 0.726349827753138,\n"," 'eval_precision': 0.7295564303922394,\n"," 'eval_recall': 0.7259724639821176,\n"," 'eval_runtime': 15.2283,\n"," 'eval_samples_per_second': 436.095,\n"," 'eval_steps_per_second': 6.829}"]},"metadata":{},"execution_count":36}],"source":["trainer.evaluate(eval_dataset=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6IjIG6JHioRr","outputId":"034656c0-0997-4a5b-ae22-573cc766989a","executionInfo":{"status":"error","timestamp":1676268149772,"user_tz":-540,"elapsed":51135,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["문장을 입력해주세요: 집에 보내줘\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","output_type":"stream","text":["tensor([[0.0569, 0.0399, 0.7641, 0.1027, 0.0236, 0.0128]])\n","분노 --\n","\n","\n","문장을 입력해주세요: 난 왜 이런걸까..\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["tensor([[0.0086, 0.2094, 0.1823, 0.2572, 0.1888, 0.1536]])\n","불안... ㄷㄷㄷ\n","\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-517fbe74e9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#0 입력시 종료\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m      \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장을 입력해주세요: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m          \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["def sentence_predict(sent):\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 입력된 문장 토크나이징\n","    tokenized_sent = tokenizer(\n","        sent,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        add_special_tokens=True,\n","        max_length=128\n","    )\n","\n","    # 모델이 위치한 GPU로 이동\n","    tokenized_sent.to(device)\n","\n","    # 예측\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids = tokenized_sent[\"input_ids\"],\n","            attention_mask=tokenized_sent[\"attention_mask\"],\n","            token_type_ids=tokenized_sent[\"token_type_ids\"]\n","        )\n","\n","    # 결과 return\n","    logits = outputs[0]\n","    logits = logits.detach().cpu()\n","    prob = logits.softmax(dim=1)\n","    x = ['기쁨', '슬픔', '분노', '불안', '당황', '상처']\n","    y = [prob[0][0], prob[0][1], prob[0][2],prob[0][3],prob[0][4],prob[0][5]]\n","\n","    bar = plt.bar(x,y,color='slateblue')\n","    for rect in bar:\n","        height = rect.get_height()\n","        plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f' % height, ha='center', va='bottom', size = 10)\n","    plt.title('감정 확률 분포포')\n","    plt.legend(['감정'])\n","    plt.show()\n","\n","    print(prob)\n","    result = logits.argmax(-1)\n","    if result == 0:\n","        result = \"기쁨 ㅎㅎ\"\n","    elif result == 1:\n","        result = \"슬픔 ㅠㅠ\"\n","    elif result == 2:\n","        result = \"분노 --\"\n","    elif result == 3: \n","        result = \"불안... ㄷㄷㄷ\"\n","    elif result == 4:\n","        result = \"당황?!\"\n","    elif result == 5:\n","        result = \"상처...ㅠㅠㅠ\"\n","    return result\n","\n","#0 입력시 종료\n","while True:\n","     sentence = input(\"문장을 입력해주세요: \")\n","     if sentence == \"0\": \n","         break\n","     print(sentence_predict(sentence))\n","     print(\"\\n\")\n","    "]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"17-Rh-eoqhbtQ724ui-XyRPpd2hoaVfT0","timestamp":1676440909385},{"file_id":"1W8LRwVySJAweZCP0l3bwQaPV5LQQE8R2","timestamp":1675936517655}],"mount_file_id":"17-Rh-eoqhbtQ724ui-XyRPpd2hoaVfT0","authorship_tag":"ABX9TyNEcClQlTI06H6tD4jyH66Q"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"57c1aec930af480498a534696914dcee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5a09106148a4e20aef677ef8b708341","IPY_MODEL_f17d21396ddb4943bb6bb8b4d8d70138","IPY_MODEL_62f4d042e799404b85c4f98c250665e0"],"layout":"IPY_MODEL_679e6102da26434486690477220b2a69"}},"a5a09106148a4e20aef677ef8b708341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_629c6afc4cd448fcb2226770da47c4ef","placeholder":"​","style":"IPY_MODEL_65acfec66e2940fea8386b2dcbc545b7","value":"Downloading (…)okenizer_config.json: 100%"}},"f17d21396ddb4943bb6bb8b4d8d70138":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_700273b1d89e4a98aaf429e9c3c531df","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_209de8577f5f44098492b54f0a8226c0","value":288}},"62f4d042e799404b85c4f98c250665e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8415d40351f4c4780b465e97441468e","placeholder":"​","style":"IPY_MODEL_81a488705e884c3bb2327e77b77850a2","value":" 288/288 [00:00&lt;00:00, 4.84kB/s]"}},"679e6102da26434486690477220b2a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"629c6afc4cd448fcb2226770da47c4ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65acfec66e2940fea8386b2dcbc545b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"700273b1d89e4a98aaf429e9c3c531df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209de8577f5f44098492b54f0a8226c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8415d40351f4c4780b465e97441468e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a488705e884c3bb2327e77b77850a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6452ad161c1741d088b9d1f8143bb11a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_018bc9a2b8384ffca92758977e5b397a","IPY_MODEL_ae08e5667e794c5fabf64e54c67ccaec","IPY_MODEL_51959f1409f8466580206ea16d72a2eb"],"layout":"IPY_MODEL_116576bf73e94256a41f107fcd5735e3"}},"018bc9a2b8384ffca92758977e5b397a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab911a53df904f7d820fb62ee0d6f20d","placeholder":"​","style":"IPY_MODEL_43337cdfb4f6470bb9226a38f1420c2e","value":"Downloading (…)lve/main/config.json: 100%"}},"ae08e5667e794c5fabf64e54c67ccaec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0af86aa8072042498dcfb29165c327cb","max":504,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be45dea373494ec9932c8da89ec3d7f6","value":504}},"51959f1409f8466580206ea16d72a2eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_539363cd9274415cacf894a1d8c6e82d","placeholder":"​","style":"IPY_MODEL_6574eb1017cc4db692286cea1f6bd1c5","value":" 504/504 [00:00&lt;00:00, 15.9kB/s]"}},"116576bf73e94256a41f107fcd5735e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab911a53df904f7d820fb62ee0d6f20d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43337cdfb4f6470bb9226a38f1420c2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0af86aa8072042498dcfb29165c327cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be45dea373494ec9932c8da89ec3d7f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"539363cd9274415cacf894a1d8c6e82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6574eb1017cc4db692286cea1f6bd1c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6aa9a7149b5546018cf3c2c6a47509c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84974d16c1e9496eb5216d6ba1fa46c0","IPY_MODEL_efcd6695385a42f28f75179e5c0bde68","IPY_MODEL_9ffcdd014b8f49a8b03196d486ce5195"],"layout":"IPY_MODEL_9ca48c98404d48948ba48e733d4ba439"}},"84974d16c1e9496eb5216d6ba1fa46c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93191853ab014e8c8f1ea60fd8069232","placeholder":"​","style":"IPY_MODEL_b64b1011650d4ff7b9b5688fdee9ff5e","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"efcd6695385a42f28f75179e5c0bde68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b7d05bb589341b483e7b886ba45e42b","max":449580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e453643cdeea447cb195b61d1e4f902e","value":449580}},"9ffcdd014b8f49a8b03196d486ce5195":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_133d2a8d3cce4bc58e7c4f618d8d59ff","placeholder":"​","style":"IPY_MODEL_4104db99b69d495aaab745ffaa1650d1","value":" 450k/450k [00:00&lt;00:00, 2.51MB/s]"}},"9ca48c98404d48948ba48e733d4ba439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93191853ab014e8c8f1ea60fd8069232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b64b1011650d4ff7b9b5688fdee9ff5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b7d05bb589341b483e7b886ba45e42b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e453643cdeea447cb195b61d1e4f902e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"133d2a8d3cce4bc58e7c4f618d8d59ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4104db99b69d495aaab745ffaa1650d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e3605b73c6e428f8a2b93ec5f8fd223":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a354c4f6f1a04103b3ff51670b2d996b","IPY_MODEL_fe2b30d5921a43e6be1e14a65c2614b7","IPY_MODEL_f7a5bd05899e429c86159c5a5ec338dd"],"layout":"IPY_MODEL_2fb1e402bdb74114a7e5c559145e7c23"}},"a354c4f6f1a04103b3ff51670b2d996b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd23a2c4115744e1b3454345475cb293","placeholder":"​","style":"IPY_MODEL_341c5c65c2924f41afbb6f3e280199a8","value":"Downloading (…)cial_tokens_map.json: 100%"}},"fe2b30d5921a43e6be1e14a65c2614b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce369847c3c9481c959502cea0bf66e9","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d76e6b18fbf4fe58448cc3823cc58b4","value":124}},"f7a5bd05899e429c86159c5a5ec338dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4904f7fe5cc04023bf2b871b87d81c4b","placeholder":"​","style":"IPY_MODEL_a2ae3e91f0bc490b9086b6ddde5195d2","value":" 124/124 [00:00&lt;00:00, 1.95kB/s]"}},"2fb1e402bdb74114a7e5c559145e7c23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd23a2c4115744e1b3454345475cb293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341c5c65c2924f41afbb6f3e280199a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce369847c3c9481c959502cea0bf66e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d76e6b18fbf4fe58448cc3823cc58b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4904f7fe5cc04023bf2b871b87d81c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ae3e91f0bc490b9086b6ddde5195d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}