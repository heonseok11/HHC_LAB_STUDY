{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJQmVka3HKQA","executionInfo":{"status":"ok","timestamp":1676269168855,"user_tz":-540,"elapsed":21018,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"ae8f5a97-9eb0-49d8-a9d9-481c380af2b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["47e32011acc94be2b8a942e552a50247","5b47d8dc7b55459489fb567a920731f7","9368b3f3ac0f42a6b10f5d9e6837d016","4c9479b729064d5a98cbe00c9f94d51d","277de49dc7874d68b66313340dbe7f0b","c192e31ddd1e43b0ba2b057f39daf8e9","22101bafc7c34aa49a753a6fa524ea89","98ad5692247c4a11bf6c0438c3651e17","999507516dee45c794946a537240ac0a","f5aa0fd22f3a422bab306a289cd7ef6f","4e1b2bf011a24315aa1bdd47b0e8382e","aa873640634343f0a4db44b5c1a30361","eee82a060294422f8a6b8b029aa570bf","43cb9d6fdb814f5ebefb61f6f83abd4b","97b9d20649ab4a37a10594444c00c644","c457d827794d44d69644ce53f6598b8a","222fb1cc0cd14516ab6b2e61bbc93707","f843c38a426b41dd8b749a04fd6394be","0e4dc3c824f14fd49555ad7039446b8d","70242ca5e3514f0ab7c5b65c7dc1b3f4","26e36368210b44139a47264bdf6647a8","3cfa3cdfd815415e84317bd70fbfe248","1a848cb141fc4b4fad16b9a1bc9f9407","bb3edce2aff142b98f2316a743de8143","8d18e2606609481183ac34107d550225","d53857bd643b428f9d087dd365ae62bd","45dcb77a7e9d4bd18c83bdefa0ba45d5","5d0ffb209017406781f097f41e8d8939","2b2a020402fd432f88e2c55b9f6d2097","ed119db4266b40dfb6f74dc1ab88e60d","04d9c32fcf2740978b41c21bbcde87fa","b09aead8d2014e56bc8b0f26789b34d8","fe982eea08d647eaa1294163ed9b9a71","ea631338ba384ba3ab2c7c869ec34284","d4194e16390147f09dc2f172b8b4907a","138092d47c8441378f6d458267204c68","5e10d9e2a6f745c9ac253a18a932ed14","cf5e2d4f3f634ec6a9a53ffb014597ff","a80adf3a7b2a44529c597f2e56c4394e","0c6680e0e60a41c89444977937201889","7ac026c586af48f8b06cb507cf9c9c1b","b43478cbef7746fb88378a0f15e93038","4cc48123745a450a8791cca0e1ef2617","4795c356a4f442c285b97bc1c502f44d"]},"executionInfo":{"elapsed":12045,"status":"ok","timestamp":1676269183558,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"pjC_IT2VFXFO","outputId":"72f475c4-7c46-47da-9b98-c0ea66d11bc5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e32011acc94be2b8a942e552a50247"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/504 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa873640634343f0a4db44b5c1a30361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/450k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a848cb141fc4b4fad16b9a1bc9f9407"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea631338ba384ba3ab2c7c869ec34284"}},"metadata":{}}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, TrainingArguments, Trainer\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11293,"status":"ok","timestamp":1676269199052,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"9QjvUHuIHeh0","outputId":"d11ba332-97e2-41bb-bc4a-74c869ea6b6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["- 기쁨 : 0 \n","- 슬픔 : 1 \n","- 분노 : 2\n","- 불안 : 3\n","- 당황 : 4\n","- 상처 : 5\n"],"metadata":{"id":"bpw-iM-y9U9H"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1676269204630,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"tSzJEzP2yhIS","outputId":"3398b5cb-582d-4cda-e2e4-34932ce08dbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id                                               text  labels\n","0          1                          일은 왜 해도 해도 끝이 없을까? 화가 난다.       2\n","1          2     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.       2\n","2          3  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...       2\n","3          4  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...       2\n","4          5              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.       2\n","...      ...                                                ...     ...\n","51625  51626     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.       2\n","51626  51627        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.       3\n","51627  51628   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.       5\n","51628  51629  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.       3\n","51629  51630  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.       5\n","\n","[51630 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8f9e5c26-5aea-4cc8-baad-f6dbedcfe214\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>51625</th>\n","      <td>51626</td>\n","      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>51626</th>\n","      <td>51627</td>\n","      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>51627</th>\n","      <td>51628</td>\n","      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>51628</th>\n","      <td>51629</td>\n","      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>51629</th>\n","      <td>51630</td>\n","      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>51630 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f9e5c26-5aea-4cc8-baad-f6dbedcfe214')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f9e5c26-5aea-4cc8-baad-f6dbedcfe214 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f9e5c26-5aea-4cc8-baad-f6dbedcfe214');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["train_df = pd.read_csv('/content/drive/MyDrive/sentiment_kcelectra/감성대화말뭉치_Training.csv')\n","train_df"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1676269206860,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"prO7W9dWOD0Q","outputId":"4e94548b-fa17-49bb-b259-5f3a34e40584"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                               text  labels\n","0        1  이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...       3\n","1        2              회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.       3\n","2        3                      상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워.       3\n","3        4          이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.       3\n","4        5                       직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼.       3\n","...    ...                                                ...     ...\n","6636  6637  나랑 비슷한 시기에 결혼하는 친구는 시댁에서 집을 해줘서 너무 부러워. 우리는 대출...       4\n","6637  6638    친구 한 명이 결혼해서 아이를 가졌는데 너무 행복해 보이더라. 기분이 좋지만은 않아.       4\n","6638  6639      남들은 결혼 전에 일억을 모았다는데 난 뭐를 한 것인지 모르겠어. 자괴감만 드네.       4\n","6639  6640  나보다 결혼을 먼저 한 친구가 부러워. 그 친구 남편은 직장도 내 남편보다 좋고 키...       4\n","6640  6641                        친구들 모두 결혼하고 나만 혼자 남아서 쓸쓸하네.       4\n","\n","[6641 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-cdbf8c61-5695-4fa5-b9d7-644088e2ece3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼.</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6636</th>\n","      <td>6637</td>\n","      <td>나랑 비슷한 시기에 결혼하는 친구는 시댁에서 집을 해줘서 너무 부러워. 우리는 대출...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6637</th>\n","      <td>6638</td>\n","      <td>친구 한 명이 결혼해서 아이를 가졌는데 너무 행복해 보이더라. 기분이 좋지만은 않아.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6638</th>\n","      <td>6639</td>\n","      <td>남들은 결혼 전에 일억을 모았다는데 난 뭐를 한 것인지 모르겠어. 자괴감만 드네.</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6639</th>\n","      <td>6640</td>\n","      <td>나보다 결혼을 먼저 한 친구가 부러워. 그 친구 남편은 직장도 내 남편보다 좋고 키...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6640</th>\n","      <td>6641</td>\n","      <td>친구들 모두 결혼하고 나만 혼자 남아서 쓸쓸하네.</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6641 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdbf8c61-5695-4fa5-b9d7-644088e2ece3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cdbf8c61-5695-4fa5-b9d7-644088e2ece3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cdbf8c61-5695-4fa5-b9d7-644088e2ece3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["test_df = pd.read_csv('/content/drive/MyDrive/sentiment_kcelectra/감성대화말뭉치_Test.csv')\n","test_df"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SOrrZgc5O0NM","executionInfo":{"status":"ok","timestamp":1676269214188,"user_tz":-540,"elapsed":4850,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["tokenized_train_sentences = tokenizer(\n","    list(train_df[\"text\"]),\n","    return_tensors= \"pt\",        # pytorch의 tensor 형태로 return\n","    max_length = 128,            # 최대 토큰 길이\n","    padding = True,              # 제로패팅\n","    truncation = True,           # 최대 토큰 길이 초과하면 자름\n","    add_special_tokens = True,   # special token 추가\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1676269215491,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"yk1YbNZRP7F0","outputId":"6790d1b1-c8b6-4529-8ce3-adc1376d4f2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=64, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '일은', '왜', '해도', '해도', '끝이', '없을까', '?', '화가', '난다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 10393, 2607, 8487, 8487, 12021, 23573, 33, 10540, 10764, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(tokenized_train_sentences[0])\n","print(tokenized_train_sentences[0].tokens)\n","print(tokenized_train_sentences[0].ids)\n","print(tokenized_train_sentences[0].attention_mask)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HU81R98nQlKQ","executionInfo":{"status":"ok","timestamp":1676269218046,"user_tz":-540,"elapsed":959,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["tokenized_test_sentences = tokenizer(\n","    list(test_df[\"text\"]),\n","    return_tensors= \"pt\",        # pytorch의 tensor 형태로 return\n","    max_length = 128,            # 최대 토큰 길이\n","    padding = True,              # 제로패팅\n","    truncation = True,           # 최대 토큰 길이 초과하면 자름\n","    add_special_tokens = True,   # special token 추가가\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1676269219903,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"WiYtIHaxQrOp","outputId":"e3438451-06e4-4bb9-f3f6-a632afa22cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=42, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '이번', '프로젝트', '##에서', '발표를', '하는데', '내가', '실수', '##하는', '바람에', '우리', '팀', '##이', '감', '##점을', '받았', '##어', '.', '너무', '미안해', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 8156, 36780, 7938, 32670, 8473, 8201, 11029, 7934, 20830, 7955, 3351, 4034, 868, 12030, 9491, 4092, 18, 8024, 21941, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(tokenized_test_sentences[0])\n","print(tokenized_test_sentences[0].tokens)\n","print(tokenized_test_sentences[0].ids)\n","print(tokenized_test_sentences[0].attention_mask)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"UkOlLzhXRyP4","executionInfo":{"status":"ok","timestamp":1676269221801,"user_tz":-540,"elapsed":276,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["class SentimentDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"rndvkzQkUN2F","executionInfo":{"status":"ok","timestamp":1676269223644,"user_tz":-540,"elapsed":281,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["train_label = train_df[\"labels\"].values\n","test_label = test_df[\"labels\"].values\n","\n","train_dataset = SentimentDataset(tokenized_train_sentences, train_label)\n","test_dataset = SentimentDataset(tokenized_test_sentences, test_label)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3138,"status":"ok","timestamp":1676269987682,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"BaRUbJtLUyy4","outputId":"d0e31d80-f4d5-4c4d-fcb5-7e1318427819"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--beomi--KcELECTRA-base-v2022/snapshots/4431b6c7ad00f82fd50880864574cef97e0a368b/config.json\n","Model config ElectraConfig {\n","  \"_name_or_path\": \"beomi/KcELECTRA-base-v2022\",\n","  \"architectures\": [\n","    \"ElectraForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 54343\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--beomi--KcELECTRA-base-v2022/snapshots/4431b6c7ad00f82fd50880864574cef97e0a368b/pytorch_model.bin\n","Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.2, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.2, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":28}],"source":["config = AutoConfig.from_pretrained('beomi/KcELECTRA-base-v2022')\n","config.hidden_dropout_prob = 0.2\n","config.num_labels = 6\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base-v2022\", config=config)\n","model.to(device)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1676270416648,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"deHdn6yNU1VJ","outputId":"92d58cdc-cefc-4d4a-80d9-4cb54494ebac"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/sentiment_kcelectra/',           # 학습결과 저장경로\n","    num_train_epochs=5,                                                 # 학습 에포크 설정\n","    per_device_train_batch_size=32,                                     # 학습 배치 사이즈 설정\n","    per_device_eval_batch_size=64,                                      # 테스트 배치 사이즈 설정  \n","    logging_dir='/content/drive/MyDrive/sentiment_kcelectra/logs',      # 학습 log 저장 경로\n","    logging_steps=500,                                                  # 학습 log 기록 단위\n","    save_total_limit=7,                                                 # 학습 결과 저장 최대 갯수\n","    resume_from_checkpoint=True\n",")   "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"mee6Z0O1XdN_","executionInfo":{"status":"ok","timestamp":1676269766930,"user_tz":-540,"elapsed":255,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support, accuracy_score"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676269767993,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"A8hdK9FqXlJZ"},"outputs":[],"source":["# 평가지표를 위한 함수\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy' : acc,\n","        'f1' : f1,\n","        'precision' : precision,\n","        'recall' : recall\n","    }"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"DXxwCGeRYZUJ","executionInfo":{"status":"ok","timestamp":1676270420988,"user_tz":-540,"elapsed":404,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["trainer = Trainer(\n","    model = model,\n","    args = args,\n","    train_dataset = train_dataset,\n","    eval_dataset = test_dataset,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3054054,"status":"ok","timestamp":1676273476263,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"5OFD1RXvYgHa","outputId":"8cb3d7ca-ad78-438f-9e9b-3cae069a41ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 51630\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 8070\n","  Number of trainable parameters = 127781382\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='8070' max='8070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8070/8070 50:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.149600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.091000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.110100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.039700</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.003500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.009100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.939300</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.890800</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.882500</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.833200</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.759800</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.768900</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.743200</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.648600</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.658500</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.653800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-500/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-1000/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-1500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-1500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-1500/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-2000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-2000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-2000/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-2500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-2500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-2500/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-3000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-3000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-3000/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-3500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-3500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-3500/pytorch_model.bin\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-4000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-4000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-4000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-500] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-4500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-4500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-4500/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-1000] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-5000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-5000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-5000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-1500] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-5500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-5500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-5500/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-2000] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-2500] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-6500/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-3000] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-7000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-7000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-7000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-3500] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-7500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-7500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-7500/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-4000] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcelectra/checkpoint-8000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-8000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcelectra/checkpoint-8000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/sentiment_kcelectra/checkpoint-4500] due to args.save_total_limit\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=8070, training_loss=0.8842216609874475, metrics={'train_runtime': 3053.8598, 'train_samples_per_second': 84.532, 'train_steps_per_second': 2.643, 'total_flos': 8490569790297600.0, 'train_loss': 0.8842216609874475, 'epoch': 5.0})"]},"metadata":{},"execution_count":34}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"elapsed":17160,"status":"ok","timestamp":1676273779656,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"pf--CjZqifCI","outputId":"c8bfc47f-b290-4d36-a058-94907c1189c2"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 6641\n","  Batch size = 64\n","<ipython-input-10-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='104' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [104/104 00:16]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"[0.93860387 0.66921972 0.7295898  0.69859919 0.67835149 0.63737374]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.95793991 0.64364641 0.73046252 0.70272727 0.67356538 0.64850976]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.92003298 0.69690927 0.72871917 0.69451932 0.68320611 0.6266137 ]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.8448866009712219,\n"," 'eval_accuracy': 0.730462279777142,\n"," 'eval_f1': array([0.93860387, 0.66921972, 0.7295898 , 0.69859919, 0.67835149,\n","        0.63737374]),\n"," 'eval_precision': array([0.95793991, 0.64364641, 0.73046252, 0.70272727, 0.67356538,\n","        0.64850976]),\n"," 'eval_recall': array([0.92003298, 0.69690927, 0.72871917, 0.69451932, 0.68320611,\n","        0.6266137 ]),\n"," 'eval_runtime': 16.8898,\n"," 'eval_samples_per_second': 393.195,\n"," 'eval_steps_per_second': 6.158,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":35}],"source":["trainer.evaluate(eval_dataset=test_dataset)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"6IjIG6JHioRr","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1676265400649,"user_tz":-540,"elapsed":56512,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"dd8040fd-931d-45ee-8715-ab203765aa0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["문장을 입력해주세요: 제발 집에 보내줘\n","tensor([[0.0398, 0.0333, 0.8742, 0.0340, 0.0068, 0.0119]])\n","분노 --\n","\n","\n","문장을 입력해주세요: 안보내줘?\n","tensor([[1.6231e-03, 1.8477e-03, 9.8900e-01, 4.7020e-03, 9.5466e-04, 1.8687e-03]])\n","분노 --\n","\n","\n","문장을 입력해주세요: 시발 장난해\n","tensor([[0.0649, 0.0463, 0.7761, 0.0168, 0.0039, 0.0921]])\n","분노 --\n","\n","\n","문장을 입력해주세요: 어떻게 그런말을 할수가 있어\n","tensor([[0.0529, 0.1073, 0.4714, 0.0128, 0.0148, 0.3410]])\n","분노 --\n","\n","\n","문장을 입력해주세요: 실망이야\n","tensor([[7.6892e-04, 9.7818e-01, 1.1300e-02, 2.5673e-03, 3.3673e-03, 3.8163e-03]])\n","슬픔 ㅠㅠ\n","\n","\n","문장을 입력해주세요: 집에 언제가?\n","tensor([[0.1157, 0.1666, 0.2102, 0.4165, 0.0187, 0.0723]])\n","불안... ㄷㄷㄷ\n","\n","\n","문장을 입력해주세요: 이건 좀 아닌듯..\n","tensor([[0.0128, 0.3400, 0.1821, 0.4024, 0.0183, 0.0445]])\n","불안... ㄷㄷㄷ\n","\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-66cc4413be1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#0 입력시 종료\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m      \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장을 입력해주세요: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m          \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["def sentence_predict(sent):\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 입력된 문장 토크나이징\n","    tokenized_sent = tokenizer(\n","        sent,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        add_special_tokens=True,\n","        max_length=128\n","    )\n","\n","    # 모델이 위치한 GPU로 이동\n","    tokenized_sent.to(device)\n","\n","    # 예측\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids = tokenized_sent[\"input_ids\"],\n","            attention_mask=tokenized_sent[\"attention_mask\"],\n","            token_type_ids=tokenized_sent[\"token_type_ids\"]\n","        )\n","\n","    # 결과 return\n","    logits = outputs[0]\n","    logits = logits.detach().cpu()\n","    prob = logits.softmax(dim=1)\n","    print(prob)\n","    result = logits.argmax(-1)\n","    if result == 0:\n","        result = \"기쁨 ㅎㅎ\"\n","    elif result == 1:\n","        result = \"슬픔 ㅠㅠ\"\n","    elif result == 2:\n","        result = \"분노 --\"\n","    elif result == 3: \n","        result = \"불안... ㄷㄷㄷ\"\n","    elif result == 4:\n","        result = \"당황?!\"\n","    elif result == 5:\n","        result = \"상처...ㅠㅠㅠ\"\n","    return result\n","\n","#0 입력시 종료\n","while True:\n","     sentence = input(\"문장을 입력해주세요: \")\n","     if sentence == \"0\": \n","         break\n","     print(sentence_predict(sentence))\n","     print(\"\\n\")\n","    "]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1W8LRwVySJAweZCP0l3bwQaPV5LQQE8R2","authorship_tag":"ABX9TyPNJg1wqrSD4eUVbAXxFdI6"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"47e32011acc94be2b8a942e552a50247":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b47d8dc7b55459489fb567a920731f7","IPY_MODEL_9368b3f3ac0f42a6b10f5d9e6837d016","IPY_MODEL_4c9479b729064d5a98cbe00c9f94d51d"],"layout":"IPY_MODEL_277de49dc7874d68b66313340dbe7f0b"}},"5b47d8dc7b55459489fb567a920731f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c192e31ddd1e43b0ba2b057f39daf8e9","placeholder":"​","style":"IPY_MODEL_22101bafc7c34aa49a753a6fa524ea89","value":"Downloading (…)okenizer_config.json: 100%"}},"9368b3f3ac0f42a6b10f5d9e6837d016":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98ad5692247c4a11bf6c0438c3651e17","max":288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_999507516dee45c794946a537240ac0a","value":288}},"4c9479b729064d5a98cbe00c9f94d51d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5aa0fd22f3a422bab306a289cd7ef6f","placeholder":"​","style":"IPY_MODEL_4e1b2bf011a24315aa1bdd47b0e8382e","value":" 288/288 [00:00&lt;00:00, 6.70kB/s]"}},"277de49dc7874d68b66313340dbe7f0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c192e31ddd1e43b0ba2b057f39daf8e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22101bafc7c34aa49a753a6fa524ea89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98ad5692247c4a11bf6c0438c3651e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"999507516dee45c794946a537240ac0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5aa0fd22f3a422bab306a289cd7ef6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1b2bf011a24315aa1bdd47b0e8382e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa873640634343f0a4db44b5c1a30361":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eee82a060294422f8a6b8b029aa570bf","IPY_MODEL_43cb9d6fdb814f5ebefb61f6f83abd4b","IPY_MODEL_97b9d20649ab4a37a10594444c00c644"],"layout":"IPY_MODEL_c457d827794d44d69644ce53f6598b8a"}},"eee82a060294422f8a6b8b029aa570bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_222fb1cc0cd14516ab6b2e61bbc93707","placeholder":"​","style":"IPY_MODEL_f843c38a426b41dd8b749a04fd6394be","value":"Downloading (…)lve/main/config.json: 100%"}},"43cb9d6fdb814f5ebefb61f6f83abd4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e4dc3c824f14fd49555ad7039446b8d","max":504,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70242ca5e3514f0ab7c5b65c7dc1b3f4","value":504}},"97b9d20649ab4a37a10594444c00c644":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e36368210b44139a47264bdf6647a8","placeholder":"​","style":"IPY_MODEL_3cfa3cdfd815415e84317bd70fbfe248","value":" 504/504 [00:00&lt;00:00, 8.05kB/s]"}},"c457d827794d44d69644ce53f6598b8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"222fb1cc0cd14516ab6b2e61bbc93707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f843c38a426b41dd8b749a04fd6394be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e4dc3c824f14fd49555ad7039446b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70242ca5e3514f0ab7c5b65c7dc1b3f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26e36368210b44139a47264bdf6647a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cfa3cdfd815415e84317bd70fbfe248":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a848cb141fc4b4fad16b9a1bc9f9407":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb3edce2aff142b98f2316a743de8143","IPY_MODEL_8d18e2606609481183ac34107d550225","IPY_MODEL_d53857bd643b428f9d087dd365ae62bd"],"layout":"IPY_MODEL_45dcb77a7e9d4bd18c83bdefa0ba45d5"}},"bb3edce2aff142b98f2316a743de8143":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d0ffb209017406781f097f41e8d8939","placeholder":"​","style":"IPY_MODEL_2b2a020402fd432f88e2c55b9f6d2097","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"8d18e2606609481183ac34107d550225":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed119db4266b40dfb6f74dc1ab88e60d","max":449580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04d9c32fcf2740978b41c21bbcde87fa","value":449580}},"d53857bd643b428f9d087dd365ae62bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09aead8d2014e56bc8b0f26789b34d8","placeholder":"​","style":"IPY_MODEL_fe982eea08d647eaa1294163ed9b9a71","value":" 450k/450k [00:00&lt;00:00, 2.57MB/s]"}},"45dcb77a7e9d4bd18c83bdefa0ba45d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d0ffb209017406781f097f41e8d8939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b2a020402fd432f88e2c55b9f6d2097":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed119db4266b40dfb6f74dc1ab88e60d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d9c32fcf2740978b41c21bbcde87fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b09aead8d2014e56bc8b0f26789b34d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe982eea08d647eaa1294163ed9b9a71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea631338ba384ba3ab2c7c869ec34284":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4194e16390147f09dc2f172b8b4907a","IPY_MODEL_138092d47c8441378f6d458267204c68","IPY_MODEL_5e10d9e2a6f745c9ac253a18a932ed14"],"layout":"IPY_MODEL_cf5e2d4f3f634ec6a9a53ffb014597ff"}},"d4194e16390147f09dc2f172b8b4907a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a80adf3a7b2a44529c597f2e56c4394e","placeholder":"​","style":"IPY_MODEL_0c6680e0e60a41c89444977937201889","value":"Downloading (…)cial_tokens_map.json: 100%"}},"138092d47c8441378f6d458267204c68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ac026c586af48f8b06cb507cf9c9c1b","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b43478cbef7746fb88378a0f15e93038","value":124}},"5e10d9e2a6f745c9ac253a18a932ed14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cc48123745a450a8791cca0e1ef2617","placeholder":"​","style":"IPY_MODEL_4795c356a4f442c285b97bc1c502f44d","value":" 124/124 [00:00&lt;00:00, 2.57kB/s]"}},"cf5e2d4f3f634ec6a9a53ffb014597ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a80adf3a7b2a44529c597f2e56c4394e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c6680e0e60a41c89444977937201889":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ac026c586af48f8b06cb507cf9c9c1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b43478cbef7746fb88378a0f15e93038":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cc48123745a450a8791cca0e1ef2617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4795c356a4f442c285b97bc1c502f44d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}