{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJQmVka3HKQA","executionInfo":{"status":"ok","timestamp":1676823404713,"user_tz":-540,"elapsed":18298,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"874ed20d-3335-4ecc-f347-534496d795e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["b76a0a524ba4466cadc4fa3d9ca22cf3","ad7f19213c334b999c9e3ca49f7c00cf","26de1eae7e9e4f7caf17cee84c72ca74","63980149f6b04861943f70eb4d151cc6","5f8be790926948109344b40514a04a87","10b270097d2d4973bb193cf74dcf5aa0","58d2a98535fc4e159b264f4cc0e47a7e","dbe7b73ba17340f191263af06eac683f","81218d55d15643198051b7ccb31fa31c","e133f6215f934241b4ed485ccdcd686c","1c8a1cec9ae846c5b4877cfa0120f458","9a2f247c939e48e28ca5c0eb44e89978","cfef3ab2ef044659b90ab0ce15a39179","52d71eb91e7942209b07dad815a2ecaf","e12e3284a0b74dccac47ebf0b7fd1b57","5b88e8df750f403ea1f92a413f67d943","56ef4dae04fa4bc99c112c6886ff8ab5","accbcbfcf96f4725a550c1a0eafecd7f","f071dc0ef00240fab4699ca78c191816","9aed37dcb96742ecae68e626bf0f3ee6","9107b8956ea3403bacfa542e5b618e58","0347c4f9f20a4304a3bdf7df57a978e9","12bd1ab5301041b7b94ee650343ed006","850ade6f283047dfa25ee22adac64fde","55614542e8ca452ea9a4d38766b22cd2","c84691f967e343899b45b7f258c5b956","69ec6dd6ee88426a92f13f89eb652862","569ba9881fdb4aafa45d546244be3bf9","e319e1ee1ae946a2a22038aed7d61395","6c241c095d7d4dbcaf528bdab8c62ac6","5faaf0232caf4e448524d07b597159cb","f5d27c027bbf4b5085ca8c891e22b323","8adf4070ec05428394153b19915b7cca"]},"executionInfo":{"elapsed":15206,"status":"ok","timestamp":1676823422979,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"pjC_IT2VFXFO","outputId":"0c105116-db08-4fb2-c2e9-cd26e587382e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b76a0a524ba4466cadc4fa3d9ca22cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2f247c939e48e28ca5c0eb44e89978"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/250k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12bd1ab5301041b7b94ee650343ed006"}},"metadata":{}}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, TrainingArguments, Trainer\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26569,"status":"ok","timestamp":1676823449537,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"9QjvUHuIHeh0","outputId":"f7901303-9cd9-4ee2-d7e9-378b92db8624"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["- 슬픔 - 0  - 5267\n","- 중립 - 1 - 4830\n","- 행복 - 2 - 6037\n","- 혐오 - 3 - 5429\n","- 분노 - 4 - 5665\n","- 공포 - 5 - 5468\n","- 놀람 - 6 - 5898\n"],"metadata":{"id":"QW82Z-uSiVrp"}},{"cell_type":"code","source":["data_df = pd.read_csv('/content/drive/MyDrive/sentiment_kcbert/emotion_data.csv', encoding = 'cp949')"],"metadata":{"id":"V5oVjZporj2n","executionInfo":{"status":"ok","timestamp":1676823450190,"user_tz":-540,"elapsed":657,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"JMCTESJftTv8","executionInfo":{"status":"ok","timestamp":1676823450190,"user_tz":-540,"elapsed":5,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"ffeb68ca-e5ea-4791-d586-7a75c8a56dc4"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    text  labels  Unnamed: 2  \\\n","0                               언니 동생으로 부르는게 맞는 일인가요..??       5         NaN   \n","1                                           그냥 내 느낌일뿐겠지?       5         NaN   \n","2                                         아직너무초기라서 그런거죠?       5         NaN   \n","3                                          유치원버스 사고 낫다던데       5         NaN   \n","4                                            근데 원래이런거맞나요       5         NaN   \n","...                                                  ...     ...         ...   \n","38589               솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..       3         NaN   \n","38590                                        재미가 없으니 망하지       3         NaN   \n","38591  공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...       3         NaN   \n","38592               코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ       3         NaN   \n","38593               와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요       3         NaN   \n","\n","       Unnamed: 3  Unnamed: 4   공포    5468  \n","0             NaN         NaN   놀람  5898.0  \n","1             NaN         NaN   분노  5665.0  \n","2             NaN         NaN   슬픔  5267.0  \n","3             NaN         NaN   중립  4830.0  \n","4             NaN         NaN   행복  6037.0  \n","...           ...         ...  ...     ...  \n","38589         NaN         NaN  NaN     NaN  \n","38590         NaN         NaN  NaN     NaN  \n","38591         NaN         NaN  NaN     NaN  \n","38592         NaN         NaN  NaN     NaN  \n","38593         NaN         NaN  NaN     NaN  \n","\n","[38594 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-3cb4cd27-e1dd-404a-8135-1ce7916f9c44\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","      <th>공포</th>\n","      <th>5468</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>놀람</td>\n","      <td>5898.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>그냥 내 느낌일뿐겠지?</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>분노</td>\n","      <td>5665.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>아직너무초기라서 그런거죠?</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>슬픔</td>\n","      <td>5267.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>유치원버스 사고 낫다던데</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>중립</td>\n","      <td>4830.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>근데 원래이런거맞나요</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>행복</td>\n","      <td>6037.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>38589</th>\n","      <td>솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38590</th>\n","      <td>재미가 없으니 망하지</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38591</th>\n","      <td>공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38592</th>\n","      <td>코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38593</th>\n","      <td>와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>38594 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cb4cd27-e1dd-404a-8135-1ce7916f9c44')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3cb4cd27-e1dd-404a-8135-1ce7916f9c44 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3cb4cd27-e1dd-404a-8135-1ce7916f9c44');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train_df = data_df.sample(frac=0.8,random_state=11)\n","len(train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jv1TXjB7vysy","executionInfo":{"status":"ok","timestamp":1676823450191,"user_tz":-540,"elapsed":5,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"bcc9debb-4fb1-4433-d7d3-ae78cfa9ce6b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30875"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["for i in range(6):\n","    print(len(train_df.loc[train_df['labels'] == i])) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SWLhSEfyOyL","executionInfo":{"status":"ok","timestamp":1676823450686,"user_tz":-540,"elapsed":7,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"a784a7b0-775b-4add-f75e-1f08e2ca8373"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["4205\n","3868\n","4820\n","4370\n","4553\n","4344\n"]}]},{"cell_type":"code","source":["test_df = data_df.drop(train_df.index)\n","len(test_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxboD_bDwFT8","executionInfo":{"status":"ok","timestamp":1676823450686,"user_tz":-540,"elapsed":6,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"4cc5486c-93a5-45a1-97d3-bdaad88874a2"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7719"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["for i in range(6):\n","    print(len(test_df.loc[test_df['labels'] == i])) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyLU9qdMy0Jx","executionInfo":{"status":"ok","timestamp":1676823450686,"user_tz":-540,"elapsed":5,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"c2387618-0efd-48a7-845f-ccc9e230c7a4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["1062\n","962\n","1217\n","1059\n","1112\n","1124\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"SOrrZgc5O0NM","executionInfo":{"status":"ok","timestamp":1676823454760,"user_tz":-540,"elapsed":4078,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["tokenized_train_sentences = tokenizer(\n","    list(train_df[\"text\"]),\n","    return_tensors= \"pt\",        # pytorch의 tensor 형태로 return\n","    max_length = 128,            # 최대 토큰 길이\n","    padding = True,              # 제로패팅\n","    truncation = True,           # 최대 토큰 길이 초과하면 자름\n","    add_special_tokens = True,   # special token 추가\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676823456374,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"yk1YbNZRP7F0","outputId":"ee2e73c2-a25f-477d-c06f-2048b3342d41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '최순실', '특별', '##법을', '입법', '##해서', '.', '.', '극', '##형에', '처', '##해야', '한다', '이말', '##입니다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 9031, 11317, 10553, 15341, 7987, 17, 17, 392, 23929, 2874, 8021, 8129, 21179, 8074, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(tokenized_train_sentences[0])\n","print(tokenized_train_sentences[0].tokens)\n","print(tokenized_train_sentences[0].ids)\n","print(tokenized_train_sentences[0].attention_mask)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"HU81R98nQlKQ","executionInfo":{"status":"ok","timestamp":1676823456835,"user_tz":-540,"elapsed":463,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["tokenized_test_sentences = tokenizer(\n","    list(test_df[\"text\"]),\n","    return_tensors= \"pt\",        # pytorch의 tensor 형태로 return\n","    max_length = 128,            # 최대 토큰 길이\n","    padding = True,              # 제로패팅\n","    truncation = True,           # 최대 토큰 길이 초과하면 자름\n","    add_special_tokens = True,   # special token 추가가\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676823456836,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"WiYtIHaxQrOp","outputId":"677f2fc8-524c-4b6c-9697-3556ccb7df0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['[CLS]', '내가', '##불안', '##해서', '##꾸', '##는걸', '##까', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","[2, 8227, 21346, 7987, 4070, 15315, 4109, 17, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(tokenized_test_sentences[0])\n","print(tokenized_test_sentences[0].tokens)\n","print(tokenized_test_sentences[0].ids)\n","print(tokenized_test_sentences[0].attention_mask)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"UkOlLzhXRyP4","executionInfo":{"status":"ok","timestamp":1676823491788,"user_tz":-540,"elapsed":486,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["class SentimentDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rndvkzQkUN2F","executionInfo":{"status":"ok","timestamp":1676823494128,"user_tz":-540,"elapsed":1,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["train_label = train_df[\"labels\"].values\n","test_label = test_df[\"labels\"].values\n","\n","train_dataset = SentimentDataset(tokenized_train_sentences, train_label)\n","test_dataset = SentimentDataset(tokenized_test_sentences, test_label)"]},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(\"beomi/kcbert-base\", num_labels=7)\n","model.to(device)"],"metadata":{"id":"bZxXtsvINWYX","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["da147e8306ed4128a86e02b6ba73d8f9","8a87b42a6b36475b9b62df816ced5116","cc143a2fe2bb4b37b9bba65379e134aa","9b177048acad4863804d73f1620a1edb","361cb715fc064cf2a1c06283d1a1afd9","a56137b771cc4b3a939738b6375a5e7a","76b8fed6266c4dbaab0859be8abdf699","e8fd864d38084bb38b8e234b76b500d2","5c7a5d54fd724828ac113f680d3b5432","610aeef86adb433da0a743a4da3fff5a","f3c9778d73294b51aa6910c4d7bf7b71"]},"executionInfo":{"status":"ok","timestamp":1676823601784,"user_tz":-540,"elapsed":12182,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"57db0f8e-0d4b-41b1-8059-6b34ded2ce35"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--beomi--kcbert-base/snapshots/99fc27ea7d643d8377ade8912c6c445a5e3861be/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"beomi/kcbert-base\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 300,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30000\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da147e8306ed4128a86e02b6ba73d8f9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--beomi--kcbert-base/snapshots/99fc27ea7d643d8377ade8912c6c445a5e3861be/pytorch_model.bin\n","Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(300, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":482,"status":"ok","timestamp":1676823608695,"user":{"displayName":"SG서기","userId":"09544633388382643408"},"user_tz":-540},"id":"deHdn6yNU1VJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"78285303-ccf0-4c84-9609-a0d3ccf56ea2"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/sentiment_kcbert',           # 학습결과 저장경로\n","    num_train_epochs=5,                                                 # 학습 에포크 설정\n","    per_device_train_batch_size=32,                                     # 학습 배치 사이즈 설정\n","    per_device_eval_batch_size=64,                                      # 테스트 배치 사이즈 설정  \n","    logging_dir='/content/drive/MyDrive/sentiment_kcbert/logs',      # 학습 log 저장 경로\n","    logging_steps=250,                                                  # 학습 log 기록 단위\n","    save_total_limit=10,                                                 # 학습 결과 저장 최대 갯수\n","    resume_from_checkpoint=True\n",")   "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"mee6Z0O1XdN_","executionInfo":{"status":"ok","timestamp":1676823628691,"user_tz":-540,"elapsed":586,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support, accuracy_score"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"A8hdK9FqXlJZ","executionInfo":{"status":"ok","timestamp":1676823630066,"user_tz":-540,"elapsed":1,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["# 평가지표를 위한 함수\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy' : acc,\n","        'f1' : f1,\n","        'precision' : precision,\n","        'recall' : recall\n","    }"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"DXxwCGeRYZUJ","executionInfo":{"status":"ok","timestamp":1676823631511,"user_tz":-540,"elapsed":1,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[],"source":["trainer = Trainer(\n","    model = model,\n","    args = args,\n","    train_dataset = train_dataset,\n","    eval_dataset = test_dataset,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5OFD1RXvYgHa","outputId":"716aed7f-592d-4f76-9b7b-cd8082d2bfeb","executionInfo":{"status":"ok","timestamp":1676826826077,"user_tz":-540,"elapsed":3192664,"user":{"displayName":"SG서기","userId":"09544633388382643408"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 30875\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4825\n","  Number of trainable parameters = 108923911\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4825' max='4825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4825/4825 53:11, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>1.335700</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.225700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.194400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.151000</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.876300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.883700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.849100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.773800</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.498600</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.489000</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.500800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.372500</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.218000</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.216900</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.224600</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.142500</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.089900</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.086500</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.078600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-500/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-1000/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-1500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-1500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-1500/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-2000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-2000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-2000/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-2500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-2500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-2500/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-3000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-3000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-3000/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-3500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-3500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-3500/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-4000\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-4000/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-4000/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","Saving model checkpoint to /content/drive/MyDrive/sentiment_kcbert/checkpoint-4500\n","Configuration saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-4500/config.json\n","Model weights saved in /content/drive/MyDrive/sentiment_kcbert/checkpoint-4500/pytorch_model.bin\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4825, training_loss=0.581881980303038, metrics={'train_runtime': 3192.533, 'train_samples_per_second': 48.355, 'train_steps_per_second': 1.511, 'total_flos': 1.0154898156e+16, 'train_loss': 0.581881980303038, 'epoch': 5.0})"]},"metadata":{},"execution_count":27}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"pf--CjZqifCI","outputId":"364ef559-10b0-4057-8a52-237ceae3eefb"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 7719\n","  Batch size = 64\n","<ipython-input-14-8f22ac0f3218>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='118' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [118/121 00:57 < 00:01, 2.04 it/s]\n","    </div>\n","    "]},"metadata":{}}],"source":["trainer.evaluate(eval_dataset=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IjIG6JHioRr","colab":{"base_uri":"https://localhost:8080/","height":940},"executionInfo":{"status":"error","timestamp":1676610651718,"user_tz":-540,"elapsed":37433,"user":{"displayName":"SG서기","userId":"09544633388382643408"}},"outputId":"8b790b08-557d-44ec-da98-f385b346a0be"},"outputs":[{"output_type":"stream","name":"stdout","text":["문장을 입력해주세요: 안녕하세요\n","tensor([[4.0922e-03, 5.6184e-03, 9.8639e-01, 1.5649e-04, 3.0154e-04, 2.5095e-03,\n","         9.3442e-04]])\n","행복\n","\n","\n","문장을 입력해주세요: 헉\n","tensor([[3.9641e-04, 4.4009e-04, 4.2540e-04, 4.8594e-04, 7.0759e-04, 3.3625e-03,\n","         9.9418e-01]])\n","놀람\n","\n","\n","문장을 입력해주세요: 시발\n","tensor([[5.2062e-03, 7.5220e-04, 7.6104e-04, 5.4827e-03, 9.8099e-01, 3.0987e-03,\n","         3.7059e-03]])\n","분노\n","\n","\n","문장을 입력해주세요: 장난해?\n","tensor([[1.2689e-03, 2.9341e-03, 3.6187e-04, 1.8164e-01, 7.4208e-01, 8.9744e-03,\n","         6.2743e-02]])\n","분노\n","\n","\n","문장을 입력해주세요: 집에 가고 싶어..\n","tensor([[9.9820e-01, 3.1445e-04, 3.0976e-04, 3.3057e-04, 1.5858e-04, 4.4775e-04,\n","         2.3802e-04]])\n","슬픔\n","\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-dde98c517213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#0 입력시 종료\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m      \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"문장을 입력해주세요: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m          \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["def sentence_predict(sent):\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 입력된 문장 토크나이징\n","    tokenized_sent = tokenizer(\n","        sent,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        add_special_tokens=True,\n","        max_length=128\n","    )\n","\n","    # 모델이 위치한 GPU로 이동\n","    tokenized_sent.to(device)\n","\n","    # 예측\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids = tokenized_sent[\"input_ids\"],\n","            attention_mask=tokenized_sent[\"attention_mask\"],\n","            token_type_ids=tokenized_sent[\"token_type_ids\"]\n","        )\n","\n","    # 결과 return\n","    logits = outputs[0]\n","    logits = logits.detach().cpu()\n","    prob = logits.softmax(dim=1)\n","    print(prob)\n","    result = logits.argmax(-1)\n","    if result == 0:\n","        result = \"슬픔\"\n","    elif result == 1:\n","        result = \"중립\"\n","    elif result == 2:\n","        result = \"행복\"\n","    elif result == 3: \n","        result = \"혐오\"\n","    elif result == 4:\n","        result = \"분노\"\n","    elif result == 5:\n","        result = \"공포\"\n","    elif result == 6:\n","        result = \"놀람\"\n","    return result\n","\n","#0 입력시 종료\n","while True:\n","     sentence = input(\"문장을 입력해주세요: \")\n","     if sentence == \"0\": \n","         break\n","     print(sentence_predict(sentence))\n","     print(\"\\n\")\n","    "]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1W8LRwVySJAweZCP0l3bwQaPV5LQQE8R2","timestamp":1676440087407}],"mount_file_id":"1W8LRwVySJAweZCP0l3bwQaPV5LQQE8R2","authorship_tag":"ABX9TyNbyDzdrVy4BUyYbe1qdwut"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b76a0a524ba4466cadc4fa3d9ca22cf3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad7f19213c334b999c9e3ca49f7c00cf","IPY_MODEL_26de1eae7e9e4f7caf17cee84c72ca74","IPY_MODEL_63980149f6b04861943f70eb4d151cc6"],"layout":"IPY_MODEL_5f8be790926948109344b40514a04a87"}},"ad7f19213c334b999c9e3ca49f7c00cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10b270097d2d4973bb193cf74dcf5aa0","placeholder":"​","style":"IPY_MODEL_58d2a98535fc4e159b264f4cc0e47a7e","value":"Downloading (…)okenizer_config.json: 100%"}},"26de1eae7e9e4f7caf17cee84c72ca74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbe7b73ba17340f191263af06eac683f","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81218d55d15643198051b7ccb31fa31c","value":49}},"63980149f6b04861943f70eb4d151cc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e133f6215f934241b4ed485ccdcd686c","placeholder":"​","style":"IPY_MODEL_1c8a1cec9ae846c5b4877cfa0120f458","value":" 49.0/49.0 [00:00&lt;00:00, 1.31kB/s]"}},"5f8be790926948109344b40514a04a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10b270097d2d4973bb193cf74dcf5aa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d2a98535fc4e159b264f4cc0e47a7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbe7b73ba17340f191263af06eac683f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81218d55d15643198051b7ccb31fa31c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e133f6215f934241b4ed485ccdcd686c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c8a1cec9ae846c5b4877cfa0120f458":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a2f247c939e48e28ca5c0eb44e89978":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfef3ab2ef044659b90ab0ce15a39179","IPY_MODEL_52d71eb91e7942209b07dad815a2ecaf","IPY_MODEL_e12e3284a0b74dccac47ebf0b7fd1b57"],"layout":"IPY_MODEL_5b88e8df750f403ea1f92a413f67d943"}},"cfef3ab2ef044659b90ab0ce15a39179":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56ef4dae04fa4bc99c112c6886ff8ab5","placeholder":"​","style":"IPY_MODEL_accbcbfcf96f4725a550c1a0eafecd7f","value":"Downloading (…)lve/main/config.json: 100%"}},"52d71eb91e7942209b07dad815a2ecaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f071dc0ef00240fab4699ca78c191816","max":619,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9aed37dcb96742ecae68e626bf0f3ee6","value":619}},"e12e3284a0b74dccac47ebf0b7fd1b57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9107b8956ea3403bacfa542e5b618e58","placeholder":"​","style":"IPY_MODEL_0347c4f9f20a4304a3bdf7df57a978e9","value":" 619/619 [00:00&lt;00:00, 6.57kB/s]"}},"5b88e8df750f403ea1f92a413f67d943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56ef4dae04fa4bc99c112c6886ff8ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"accbcbfcf96f4725a550c1a0eafecd7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f071dc0ef00240fab4699ca78c191816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aed37dcb96742ecae68e626bf0f3ee6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9107b8956ea3403bacfa542e5b618e58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0347c4f9f20a4304a3bdf7df57a978e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12bd1ab5301041b7b94ee650343ed006":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_850ade6f283047dfa25ee22adac64fde","IPY_MODEL_55614542e8ca452ea9a4d38766b22cd2","IPY_MODEL_c84691f967e343899b45b7f258c5b956"],"layout":"IPY_MODEL_69ec6dd6ee88426a92f13f89eb652862"}},"850ade6f283047dfa25ee22adac64fde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_569ba9881fdb4aafa45d546244be3bf9","placeholder":"​","style":"IPY_MODEL_e319e1ee1ae946a2a22038aed7d61395","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"55614542e8ca452ea9a4d38766b22cd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c241c095d7d4dbcaf528bdab8c62ac6","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5faaf0232caf4e448524d07b597159cb","value":249928}},"c84691f967e343899b45b7f258c5b956":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d27c027bbf4b5085ca8c891e22b323","placeholder":"​","style":"IPY_MODEL_8adf4070ec05428394153b19915b7cca","value":" 250k/250k [00:00&lt;00:00, 376kB/s]"}},"69ec6dd6ee88426a92f13f89eb652862":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569ba9881fdb4aafa45d546244be3bf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e319e1ee1ae946a2a22038aed7d61395":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c241c095d7d4dbcaf528bdab8c62ac6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5faaf0232caf4e448524d07b597159cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5d27c027bbf4b5085ca8c891e22b323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8adf4070ec05428394153b19915b7cca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da147e8306ed4128a86e02b6ba73d8f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a87b42a6b36475b9b62df816ced5116","IPY_MODEL_cc143a2fe2bb4b37b9bba65379e134aa","IPY_MODEL_9b177048acad4863804d73f1620a1edb"],"layout":"IPY_MODEL_361cb715fc064cf2a1c06283d1a1afd9"}},"8a87b42a6b36475b9b62df816ced5116":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a56137b771cc4b3a939738b6375a5e7a","placeholder":"​","style":"IPY_MODEL_76b8fed6266c4dbaab0859be8abdf699","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"cc143a2fe2bb4b37b9bba65379e134aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8fd864d38084bb38b8e234b76b500d2","max":438218004,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c7a5d54fd724828ac113f680d3b5432","value":438218004}},"9b177048acad4863804d73f1620a1edb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_610aeef86adb433da0a743a4da3fff5a","placeholder":"​","style":"IPY_MODEL_f3c9778d73294b51aa6910c4d7bf7b71","value":" 438M/438M [00:05&lt;00:00, 82.8MB/s]"}},"361cb715fc064cf2a1c06283d1a1afd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a56137b771cc4b3a939738b6375a5e7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b8fed6266c4dbaab0859be8abdf699":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8fd864d38084bb38b8e234b76b500d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c7a5d54fd724828ac113f680d3b5432":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"610aeef86adb433da0a743a4da3fff5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3c9778d73294b51aa6910c4d7bf7b71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}